<!doctype html><html lang=en-us><head><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Deep NLP Chatbot Using a Seq2Seq Model","datePublished":"2020-08-30T00:00:00-05:00","dateModified":"2020-08-30T00:00:00-05:00","author":{"@type":"Person","name":"Daniel Zou","image":"https://dlzou.github.io/img/profile.jpg"},"mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/dlzou.github.io\/2020\/08\/30\/deep-nlp-chatbot-using-a-seq2seq-model\/"},"publisher":{"@type":"Organization","name":"Daniel Zou","logo":{"@type":"ImageObject","url":"https://dlzou.github.io/img/profile.jpg"}},"description":"Machine learning (ML) has been the tech buzzword of the decade. I first heard the term in reference to DeepMind\u0026rsquo;s legendary Go program, and it\u0026rsquo;s been on my radar ever since. This summer, I tackled a project to build a chatbot program that can respond to English human dialogue inputs with sentences. Sounds simple (it sure did to me at first), but there\u0026rsquo;s a lot under the hood. (Updated 2020-12-30)\n","keywords":[]}</script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo 0.101.0 with theme Tranquilpeak 0.5.3-BETA"><meta name=author content="Daniel Zou"><meta name=keywords content><meta name=description content="Machine learning (ML) has been the tech buzzword of the decade. I first heard the term in reference to DeepMind&rsquo;s legendary Go program, and it&rsquo;s been on my radar ever since. This summer, I tackled a project to build a chatbot program that can respond to English human dialogue inputs with sentences. Sounds simple (it sure did to me at first), but there&rsquo;s a lot under the hood. (Updated 2020-12-30)"><meta property="og:description" content="Machine learning (ML) has been the tech buzzword of the decade. I first heard the term in reference to DeepMind&rsquo;s legendary Go program, and it&rsquo;s been on my radar ever since. This summer, I tackled a project to build a chatbot program that can respond to English human dialogue inputs with sentences. Sounds simple (it sure did to me at first), but there&rsquo;s a lot under the hood. (Updated 2020-12-30)"><meta property="og:type" content="article"><meta property="og:title" content="Deep NLP Chatbot Using a Seq2Seq Model"><meta name=twitter:title content="Deep NLP Chatbot Using a Seq2Seq Model"><meta property="og:url" content="https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/"><meta property="twitter:url" content="https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/"><meta property="og:site_name" content="Daniel Zou"><meta property="og:description" content="Machine learning (ML) has been the tech buzzword of the decade. I first heard the term in reference to DeepMind&rsquo;s legendary Go program, and it&rsquo;s been on my radar ever since. This summer, I tackled a project to build a chatbot program that can respond to English human dialogue inputs with sentences. Sounds simple (it sure did to me at first), but there&rsquo;s a lot under the hood. (Updated 2020-12-30)"><meta name=twitter:description content="Machine learning (ML) has been the tech buzzword of the decade. I first heard the term in reference to DeepMind&rsquo;s legendary Go program, and it&rsquo;s been on my radar ever since. This summer, I tackled a project to build a chatbot program that can respond to English human dialogue inputs with sentences. Sounds simple (it sure did to me at first), but there&rsquo;s a lot under the hood. (Updated 2020-12-30)"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2020-08-30T00:00:00"><meta property="article:modified_time" content="2020-08-30T00:00:00"><meta property="article:section" content="Portfolio"><meta property="article:tag" content="machine learning"><meta property="article:tag" content="nlp"><meta property="article:tag" content="tensorflow"><meta name=twitter:card content="summary"><meta property="og:image" content="https://dlzou.github.io/img/profile.jpg"><meta property="twitter:image" content="https://dlzou.github.io/img/profile.jpg"><title>Deep NLP Chatbot Using a Seq2Seq Model</title><link rel=icon href=https://dlzou.github.io/img/favicon.png><link rel=canonical href=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://dlzou.github.io/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css><link rel=stylesheet href=https://dlzou.github.io/css/style.css><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></head><body><div id=blog><header id=header data-behavior=5><i id=btn-open-sidebar class="fa fa-lg fa-bars"></i><div class=header-title><a class=header-title-link href=https://dlzou.github.io/ aria-label="Go to homepage">Daniel Zou</a></div><a class=header-right-picture href=https://dlzou.github.io/#about aria-label="Open the link: /#about"><img class=header-picture src=https://dlzou.github.io/img/profile.jpg alt="Author's picture"></a></header><nav id=sidebar data-behavior=5><div class=sidebar-container><div class=sidebar-profile><a href=https://dlzou.github.io/#about aria-label="Read more about the author"><img class=sidebar-profile-picture src=https://dlzou.github.io/img/profile.jpg alt="Author's picture"></a><h4 class=sidebar-profile-name>Daniel Zou</h4><h5 class=sidebar-profile-bio>Currently <del>working in my bedroom</del> sleeping in my office</h5></div><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dlzou.github.io/ title=Home><i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden=true></i>
<span class=sidebar-button-desc>Home</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dlzou.github.io/categories title=Categories><i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden=true></i>
<span class=sidebar-button-desc>Categories</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dlzou.github.io/tags title=Tags><i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden=true></i>
<span class=sidebar-button-desc>Tags</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dlzou.github.io/archives title=Archives><i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden=true></i>
<span class=sidebar-button-desc>Archives</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://dlzou.github.io/page/about title=About><i class="sidebar-button-icon fas fa-lg fa-user" aria-hidden=true></i>
<span class=sidebar-button-desc>About</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://github.com/dlzou target=_blank rel=noopener title=GitHub><i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden=true></i>
<span class=sidebar-button-desc>GitHub</span></a></li><li class=sidebar-button><a class=sidebar-button-link href=https://linkedin.com/in/dlzou target=_blank rel=noopener title=LinkedIn><i class="sidebar-button-icon fab fa-lg fa-linkedin" aria-hidden=true></i>
<span class=sidebar-button-desc>LinkedIn</span></a></li></ul><ul class=sidebar-buttons><li class=sidebar-button><a class=sidebar-button-link href=https://dlzou.github.io/index.xml title=RSS><i class="sidebar-button-icon fas fa-lg fa-rss" aria-hidden=true></i>
<span class=sidebar-button-desc>RSS</span></a></li></ul></div></nav><div id=main data-behavior=5 class=hasCoverMetaIn><article class=post id=top><div class="post-header main-content-wrap text-left"><h1 class=post-title>Deep NLP Chatbot Using a Seq2Seq Model</h1><div class="postShorten-meta post-meta"><time datetime=2020-08-30T00:00:00-05:00>2020-08-30</time>
<span>in</span>
<a class=category-link href=https://dlzou.github.io/categories/portfolio>Portfolio</a></div></div><div class="post-content markdown"><div class=main-content-wrap><p>Machine learning (ML) has been the tech buzzword of the decade. I first heard the term in reference to DeepMind&rsquo;s <a href=https://deepmind.com/research/case-studies/alphago-the-story-so-far>legendary Go program</a>, and it&rsquo;s been on my radar ever since. This summer, I tackled a project to build a <a href=https://github.com/dlzou/dnlp-chatbot>chatbot program</a> that can respond to English human dialogue inputs with sentences. Sounds simple (it sure did to me at first), but there&rsquo;s a lot under the hood. (<strong>Updated 2020-12-30</strong>)</p><h1 id=table-of-contents>Table of Contents</h1><nav id=TableOfContents><ul><li><a href=#why-machine-learning-and-how>Why Machine Learning, and How?</a></li><li><a href=#the-process>The Process</a></li><li><a href=#2020-12-30-update>2020-12-30 Update</a></li><li><a href=#addendum-understanding-rnns>Addendum: Understanding RNNs</a></li></ul></nav><h1 id=why-machine-learning-and-how>Why Machine Learning, and How?</h1><p>When anyone who&rsquo;s written code before is asked to build a chatbot, their first thought is probably: <strong>if statements</strong>. In fact, that&rsquo;s how many chatbots in the past and present are implemented, like many simple Discord bots or that nice phone lady who asks you to &ldquo;press 0.&rdquo;</p><blockquote class=twitter-tweet><p lang=en dir=ltr>You say: "We added AI to our product"<br>I hear: "We added a bunch more IF statements to our codebase"</p>&mdash; I Am Devloper (@iamdevloper) <a href="https://twitter.com/iamdevloper/status/830070592611172357?ref_src=twsrc%5Etfw">February 10, 2017</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script><p>An obvious issue is that the input space is limited. To build a robust program for conversations, I have to handle some randomness and intepret inputs more deeply. This is where ML comes in.</p><p>Generally speaking, ML models are complex functions that map a set of inputs to a set of outputs. How does one treat an English sentence as input data? One simplistic model that accomplishes this is <strong>bag-of-words</strong>. In this model, you make note of words in a sentence without regard to order or frequency, which can easily be done by having a vector with thousands of elements&mdash;each corresponding to a word in the dictionary&mdash;and filling each element with 1 if it&rsquo;s in the sentence, or 0 otherwise. Convert a bunch of sentences to vectors like so, and we get a dataset for training a basic neural net.</p><p>However, simple is not always better, and it&rsquo;s no-brainer that word order is important to the meaning of a sentence. Unsatisfied by bag-of-words, I moved on to a more complex model called <strong>seq2seq</strong> (sequence-to-sequence). A seq2seq model has two components: an encoder takes an input and condenses its &ldquo;information&rdquo; (a very abstract concept) into a context vector, and a decoder reads that context to generate an output. It&rsquo;s worth noting that seq2seq has many more applications like translation, image captioning, and even solving differential equations. In my project, both encoder and decoder are implemented as recurrent neural networks (RNNs).</p><p>The final piece to the puzzle is <strong>attention</strong>. In vanilla seq2seq, the encoder spits out a single vector that stores the context of the entire input, so problems occur when the input becomes longer. Attention mechanisms get around this by letting the decoder see the whole input sequence and focus on the parts it needs to. Attention is so powerful that some people want to completely ditch RNNs for it! But for now, both seem to have their place. Lilian Weng has a <a href=https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html>great post</a> that explains attention.</p><h1 id=the-process>The Process</h1><p>This being my first ML project, I relied on a lot of tutorials, articles, and papers to get off the ground. Luckily, the seq2seq model has already been studied for years, and there are many online resources to help a beginner like me accomplish my goal.</p><p>The first step was to look for a large dataset on which I can train my seq2seq model. My search engine explorations led me to the <a href=http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html>Cornell Movie-Dialogs Corpus</a>, an archive of over 200,000 lines of conversation taken assembled from hundreds of movies. I preprocessed the data by grouping the lines into conversations according to their metadata, then recording each pair of lines as the input/target pairs for my training/validation dataset. While working on data acquisition, I had a moment of realization: depending the data on which my model is trained, I can completely change its purpose! For example, if instead of CMDC I used a dataset of English-French sentence pairs, my chatbot would turn into a machine translation system, with minimal changes to the model itself.</p><p>I chose to build my model using the Python interface of TensorFlow 2, and finding my way around this huge library was its own learning curve, especially since TensorFlow provides multiple APIs for doing the same things. TensorFlow has a <a href=https://www.tensorflow.org/tutorials/text/nmt_with_attention>full guide</a> for building a basic seq2seq model, but I also made many modifications like adding bidirectional RNN layers, changing the attention mechanism, and enabling static graph optimizations. The internet had me covered for pretty much everything I needed.</p><p>The time came to train my model, but this became my biggest obstacle. Although my PC is fairly powerful among laptops, it doesn&rsquo;t compare to the specialized, distributed solutions that are standard for the industry. The amount of training required to get reasonable results would take at least a week with my current setup, and I would have limited access to my computer that whole time. There&rsquo;s still hope; if I get access to some big servers and make use of the <code>tf.distributed</code> module, I can finish training and see the final results of this project.</p><h1 id=2020-12-30-update>2020-12-30 Update</h1><p>After a four-mouth hiatus, I&rsquo;m revisiting this project with more knowledge and resources.</p><p>One major feature I added is a <strong>beam search decoder</strong>. Compared to my previous implementation that used greedy search, which locally optimizes for the next word in a sequence, <a href=https://towardsdatascience.com/an-intuitive-explanation-of-beam-search-9b1d744e7a0f>beam search</a> returns more optimal sequences overall. However, not all beam search decoders are created equal. My model only uses beam search at the evaluation stage to decode user input. A more comprehensive approach, as described by <a href=https://arxiv.org/pdf/1606.02960.pdf>Wiseman & Rush</a>, is to also use beam search during training and validation, but this involves defining a new loss function, plus some other complications.</p><p>The next part started with a small coincidence: after becoming a member of <a href=https://www.csua.berkeley.edu/>Berkeley CSUA</a> root staff this past fall, I learned that the organization maintains a GPU cluster that is open to all students. This is exactly what I need! As I&rsquo;m currently typing, my chatbot model is training remotely on an absolute unit of a computer. However, I still expect the process to take some time due to the lack of parallelizeable components in RNNs. Regardless of how smart (or dumb) my chatbot ends up being, I think this a fitting conclusion to the project.</p><h1 id=addendum-understanding-rnns>Addendum: Understanding RNNs</h1><p>RNNs are important for understanding how seq2seq works. I&rsquo;m far from qualified to give a full lesson on RNNs, but I still want to include a few remarks on what I&rsquo;ve learned.</p><p>Neural networks often get compared to biological brains and take on a connotation of intelligence. This metaphor brings huge publicity, but I didn&rsquo;t find it useful for learning; I prefer <a href=https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6>James Loy&rsquo;s interpretation</a> that neural networks are big vector functions. Feed in a vector, get out a vector.</p><p>RNNs adapt the basic neural network with artificial &ldquo;memory&rdquo; to deal with sequential data like sentences or audio. I find it convenient to think of RNNs as <a href=https://en.wikipedia.org/wiki/State-space_representation>discrete state models</a>:</p><p>$$
\vec{h}(k)=\vec{f}(\vec{x}(k),\vec{u}(k))\\
\vec{x}(k+1)=\vec{g}(\vec{x}(k),\vec{u}(k))
$$</p><p>Still vector functions, but with a twist: the next state (\(\vec{x}\)) of the model depends on its previous state as well as the new input (\(\vec{u}\)), which means the model state stores &ldquo;memory&rdquo; of the previous \(0\) through \(k\) inputs. The inputs to my chatbot program are the individual words in a sentence, and different inputs change the model state, leading to different outputs (\(\vec{h}\)). There are many variants of RNNs such as Gated Recurrent Units (which I used) and Long Short-Term Memory. <a href=https://colah.github.io/posts/2015-08-Understanding-LSTMs/>This Christopher Olah article</a> explains how these work in some detail, along with nice diagrams.</p></div></div><div id=post-footer class="post-footer main-content-wrap"><div class=post-footer-tags><span class="text-color-light text-small">TAGGED IN</span><br><a class="tag tag--primary tag--small" href=https://dlzou.github.io/tags/machine-learning/>machine learning</a>
<a class="tag tag--primary tag--small" href=https://dlzou.github.io/tags/nlp/>nlp</a>
<a class="tag tag--primary tag--small" href=https://dlzou.github.io/tags/tensorflow/>tensorflow</a></div><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dlzou.github.io/2020/09/27/computers-and-humans/ data-tooltip="Computers and Humans" aria-label="NEXT: Computers and Humans"><i class="fa fa-angle-left"></i>
<span class="hide-xs hide-sm text-small icon-ml">NEXT</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dlzou.github.io/2020/08/25/hello-world/ data-tooltip="Hello World!" aria-label="PREVIOUS: Hello World!"><span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions aria-label="Share this post"><i class="fa fa-share-alt" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Twitter" aria-label="Share on Twitter"><i class="fab fa-twitter" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.linkedin.com/sharing/share-offsite/?url=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Linkedin" aria-label="Share on Linkedin"><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.reddit.com/submit?url=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Reddit" aria-label="Share on Reddit"><i class="fab fa-reddit" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://news.ycombinator.com/submitlink?u=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Hacker News" aria-label="Share on Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#top aria-label="Back to top"><i class="fa fa-arrow-up" aria-hidden=true></i></a></li></ul></div></div></article><footer id=footer class=main-content-wrap><span class=copyrights>&copy; 2022 Daniel Zou. All Rights Reserved</span></footer></div><div id=bottom-bar class=post-bottom-bar data-behavior=5><div class=post-actions-wrap><nav><ul class="post-actions post-action-nav"><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dlzou.github.io/2020/09/27/computers-and-humans/ data-tooltip="Computers and Humans" aria-label="NEXT: Computers and Humans"><i class="fa fa-angle-left"></i>
<span class="hide-xs hide-sm text-small icon-ml">NEXT</span></a></li><li class=post-action><a class="post-action-btn btn btn--default tooltip--top" href=https://dlzou.github.io/2020/08/25/hello-world/ data-tooltip="Hello World!" aria-label="PREVIOUS: Hello World!"><span class="hide-xs hide-sm text-small icon-mr">PREVIOUS</span>
<i class="fa fa-angle-right"></i></a></li></ul></nav><ul class="post-actions post-action-share"><li class="post-action hide-lg hide-md hide-sm"><a class="post-action-btn btn btn--default btn-open-shareoptions" href=#btn-open-shareoptions aria-label="Share this post"><i class="fa fa-share-alt" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://twitter.com/intent/tweet?text=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Twitter" aria-label="Share on Twitter"><i class="fab fa-twitter" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.linkedin.com/sharing/share-offsite/?url=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Linkedin" aria-label="Share on Linkedin"><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://www.reddit.com/submit?url=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Reddit" aria-label="Share on Reddit"><i class="fab fa-reddit" aria-hidden=true></i></a></li><li class="post-action hide-xs"><a class="post-action-btn btn btn--default" target=new href="https://news.ycombinator.com/submitlink?u=https://dlzou.github.io/2020/08/30/deep-nlp-chatbot-using-a-seq2seq-model/" title="Share on Hacker News" aria-label="Share on Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li><li class=post-action><a class="post-action-btn btn btn--default" href=#top aria-label="Back to top"><i class="fa fa-arrow-up" aria-hidden=true></i></a></li></ul></div></div><div id=share-options-bar class=share-options-bar data-behavior=5><i id=btn-close-shareoptions class="fa fa-times"></i><ul class=share-options><li class=share-option><a class=share-option-btn target=new href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fdlzou.github.io%2F2020%2F08%2F30%2Fdeep-nlp-chatbot-using-a-seq2seq-model%2F" aria-label="Share on Twitter"><i class="fab fa-twitter" aria-hidden=true></i><span>Share on Twitter</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fdlzou.github.io%2F2020%2F08%2F30%2Fdeep-nlp-chatbot-using-a-seq2seq-model%2F" aria-label="Share on Linkedin"><i class="fab fa-linkedin" aria-hidden=true></i><span>Share on Linkedin</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://www.reddit.com/submit?url=https%3A%2F%2Fdlzou.github.io%2F2020%2F08%2F30%2Fdeep-nlp-chatbot-using-a-seq2seq-model%2F" aria-label="Share on Reddit"><i class="fab fa-reddit" aria-hidden=true></i><span>Share on Reddit</span></a></li><li class=share-option><a class=share-option-btn target=new href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fdlzou.github.io%2F2020%2F08%2F30%2Fdeep-nlp-chatbot-using-a-seq2seq-model%2F" aria-label="Share on Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i><span>Share on Hacker News</span></a></li></ul></div><div id=share-options-mask class=share-options-mask></div></div><div id=about><div id=about-card><div id=about-btn-close><i class="fa fa-times"></i></div><img id=about-card-picture src=https://dlzou.github.io/img/profile.jpg alt="Author's picture"><h4 id=about-card-name>Daniel Zou</h4><div id=about-card-bio>Currently <del>working in my bedroom</del> sleeping in my office</div><div id=about-card-job><i class="fa fa-briefcase"></i><br>NVIDIA</div><div id=about-card-location><i class="fa fa-map-marker-alt"></i><br>Berkeley, CA</div></div></div><div id=cover style=background-image:url(https://dlzou.github.io/img/cover.jpeg)></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js integrity="sha512-z+/WWfyD5tccCukM4VvONpEtLmbAm5LDu7eKiyMQJ9m7OfPEDL7gENyDRL3Yfe8XAuGsS2fS4xSMnl6d30kqGQ==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin=anonymous referrerpolicy=no-referrer></script>
<script src=https://dlzou.github.io/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js></script>
<script>$(document).ready(function(){hljs.configure({classPrefix:"",useBR:!1}),$("pre.code-highlight > code, pre > code").each(function(e,t){$(this).hasClass("codeblock")||$(this).addClass("codeblock"),hljs.highlightBlock(t)})})</script></body></html>